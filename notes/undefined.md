# 基于深度卷积网络的端到端SPH流体模拟

## 摘要

基于N-S方程的高效模拟一直在数值计算上耗费巨大的计算资源，近来一些利用机器学习方法加速流体模拟的方法也陆续被提出来，但是我们发现，很多方法都是采用卷积网络对欧拉方法进行驱动模拟，这些方法都无法针对SPH方法中离散粒子数据的处理，因而我们提出一种端到端的自动提取离散粒子特征的深度学习框架，驱动模拟场景中每一帧中每一个粒子的加速度，我们称其为SPHConvNet。借鉴在3-D目标检测应用中对点云数据的处理，摒弃大多数粒子法使用的手动提取粒子特征的方式，将被预测粒子作为智能体（agent），建模在不同交互场景下智能体应该有的表现，提出将SPH粒子分组到固定体元(Volume-Element)，使用全卷积网络进行自动特征提取的架构，学习场景中粒子排列不变性，建模N-S方程中各项单独的力和约束条件， 驱动每一个智能体的加速度。

## 1	介绍

基于物理的流体模拟的任务是对流体进行数值模拟并生成流体动画，<!--它与流体的数值计算，即计算流体力学（Computational Fluid Dynamic,CFD）在数学表达上看似相近，但二者有显著区别，前者-->作为计算机动画的分支，追求的是逼真的画面效果和计算效率，<!--后者作为数值计算的分支追求的是计算精度。-->几乎所有的流体模拟任务<!--和CFD问题-->的根本基础都是Navier-Stokes方程，由一组偏微分方程构成。有两类主要的计算方法来模拟这些方程：欧拉方法和拉格朗日方法。欧拉方法将空间离散化为固定不动的网格，通过差分近似将偏微分方程在空间上离散到网格网点，从而计算得到流体的各个物理量；拉格朗日方法，则对流体质点进行离散化，通常是用粒子来代表流体微元，通过计算粒子间相互作用来模拟流体[@Bridson:2011uy]，其中比较有代表性的是光滑粒子流体动力学(Smoothed-particle hydrodynamics,SPH)方法。

<!-- 简要介绍sph方法的主要过程，适当考虑加一些sph的起源及发展。-->

SPH方法中空间内每个点的物理状态都可以由离散粒子使用光滑核函数进行插值表示，将插值应用于密度场和压强场过程中所需要的邻居粒子查找及计算过程，其次就是为保证不可压缩性进行的动态调整[@Muller:2003un]。流体模拟的主要瓶颈在于为了保证模拟的稳定性和真实性，对时间步长有着严格的限制，SPH并不直接处理不可压缩条件，而是通过保持密度不变来保证不可压缩性，这和欧拉法求解泊松方程矫正速度达到相同的目的，目前比较常用的方法是预测矫正模式迭代更新压强来满足不可压缩限制[@Solenthaler:2009eb;@Ihmsen:2014bi]。



近来随着机器学习的流行，以及深度学习在不同领域都取得突破性进展，尤其是针对欧拉方法，出现了很多应用卷积网络来求解压力投影以加速模拟的方法。但是这些方法之所以会选择欧拉法进行探索，一方面是因为卷积网络在类图像数据的处理上，有着卓越的效果，另一方面，欧拉法的空间划分使得数据稳定，正好可以适用于卷积网络，二者相互结合，产生了一些结果比较优秀的驱动模拟方法，但是这些方法都无法对粒子法产生的模拟数据进行处理。

SPH方法的数据具有这样几个特点：首先，流体被粒子化，每个粒子便成为一个单独的个体，粒子运动后，数据随机离散；其次，不同模拟场景，即使整体模拟空间不变，但场景内的粒子数目变化不定，模拟过程中也会出现粒子的增加和减少；第三，尽管粒子的输入顺序不同，但表达的仍然是同一个场景。目前，处理SPH的机器方法很少，目前唯一的面向SPH方法的随机森林方法也是基于手动提取的基于上下文积分特征，并且需要在庞大的集群上进行训练，在一般的环境下并不容易实现，并且手工提取特征的方式在实践过程中，当特征维度很大时，针对每个模拟场景中的所有粒子都进行积分特征的提取，即便常量计算时间，如果不是特大集群进行并行化计算，一个只有几万个粒子的模拟场景，这样的时间消耗其实也是很难忽略不计的，一旦场景复杂，粒子数目增加，手工提取特征的效率就变得难以接受。

我们探索了一种端到端的自动提取离散粒子特征的深度学习框架，将被预测粒子视作一个智能体（agent），构建预测器，建模在不同交互场景下智能体应该有的表现。将离散的空间粒子，划分到整齐排列的空间网体中，同时设计网体特征表示层，保证粒子的排列不变性（permutation invariance），之后采用深度全卷积网络提取特征表示粒子在N-S方程中受到的各项力和约束，预测智能体的加速度。

## 2	相关工作

近几年机器学习方法被广泛应用于流体模拟。Yang等提出使用人工神经网络的数据驱动投影方法来避免欧拉方法的迭代计算，显著提升了欧拉方法中为保证不可压缩性求解Poisson方程时投影步骤的计算时间[@Yang:2016he]。Tompson[@Tompson:2016una]等同样针对近似Possion方程的求解提出一种高度定制的深度卷积网络，使用无监督的训练方法来求解Possion方程所需要的稀疏线性系统，实现实时的2D和3D模拟。Farimani[@Farimani:2017uf]使用cGAN在不需要支配方程的情况下直接模拟热传导和不可压缩流体，不过此方法依然是基于2D的数据且数据形式是欧拉方法的网格形式。Ladicky[@Ladicky:2015kv]等使用随机森林，将流体模拟视作回归问题，手工设计基于上下文的积分特征直接建模Navier-Stocks方程中各项单独的力和约束，以此使用更大的时间步长来预测每一个粒子下一状态的位置和速度。

但是这些方法似乎都没有很好的回答这样一个问题：在整个基于物理的流体模拟流程中，到底哪些过程使用机器学习才是有意义且合理的，因为在一个相对足够大的数据集，只要模型具有一定量的复杂度，能够承载这样的数据量，同时在机器学习工程领域做好一些泛化性的操作，那么即便模型没有学到任何与基于物理流体模拟有关的性质，也能对未知场景进行一个结果还算不错的预测，从这个角度来看的话，数据驱动也仅仅是构建了一个复杂的函数近似器而已。例如在Ladicky提出的随机森林方法中，手工提取计算基于上下文的积分特征是第一次近似，之后使用积分特征在回归树中进行回归近似，由此观之，预测的稳定性和结果非常依赖训练数据集，对未知场景的泛化性能仍然是不足的。

在深度学习广泛流行之前，已经有一些模式识别与流体模拟结合的讨论与探索。Eraldo[@Marinho:2014dh]指出当包括各项异性检测提高shock layer（冲击层）的分辨率时SPH可以视作无监督学习的一个非常特殊的问题；同时也提出SPH的自由粒子的本质，在交互框架中将流体模拟的结果作为一个学习知识库，为人工智能在协作框架中研究粒子作为智能体提供了机会。Kutz[@Kutz:2017dh]探讨了深度神经网络（DNN）在流体动力学的应用前景，他指出虽然暂时不能明确解释，但是DNN构建的一些驱动模型性能已经超过了传统的物理可解释模型，目前对于DNN来说仍有一些重要的挑战，比如面对不同的数据集网络需要多少层才是合适的，每一层需要多少个节点，多大的数据量才能进行正常训练，怎样保证数学模型对数据生成好的预测，DNN的预测结果包含多大的不确定性，针对训练集之外的数据泛化性怎样，怎样保证大型网络不对训练数据过拟合。同时Kutz也提出在流体模拟领域建立一个像ImageNet那样的挑战数据集具有重大意义，相对于机器学习模型的不可解释，统计和数据科学领域的统计学习则是从数据中推理出可解释的模型。

也有一部分工作讨论了数据模型和算法模型的差异，<!--（这部分内容似乎和主题已经不太相关了，但仍然想就这个问题论述一下，数据模型dmd）-->

同时SPH方法对流体进行粒子形式的离散，对离散无序分布空间点云数据的预处理是一个棘手的问题，上面提到的神经网络法和卷积网络法应用于欧拉法基本不存在数据无法输入模型进行特征学习的问题，随机森林方法进行手工特征的提取则规避了这一问题，那么除了手工提取粒子特征的方法外，能不能找到能够将场景中所有粒子输入进网络的有效表达方式。另外，如果所有粒子数据能够输入机器学习模型，如何使模型能够不依赖于输入数据的特定顺序。

虽然目前已有的机器学习流体模拟方法对这些问题没有涉及，但仍有一些前人的工作能够带来启发，尤其是3D目标检测领域，他们的工作真丝鼓舞人心。

针对点云的数据处理上，在流体模拟领域并此没有涉及，甚至于在机器学习领域也很少有工作涉及，不过近期在3-D目标检测领域，提出了几种点云数据的处理方式。Charles等[@Qi:2016vq]提出针对3D点云数据的分类和分割深度学习框架PointNet，直接处理点云数据并且能很好的检测出输入数据的排列不变性，它的基本设计思路是集合所有单个点的特征以构建全局特征，但是没有利用利用度量空间距离寻找局部邻居点提取局部特征。在PointNet之后，Charles等[@Qi:2017tf]针对PointNet无法捕获局部结构的缺陷，进一步提出PointNet++，一个递归应用PointNet的分层神经网络(metrix space?),通过利用度量空间的距离，网络可以通过增加上下文尺度来学习本地特征，同时设计集合学习层以进行多尺度特征的结合。Zhou[@Zhou:2017vn]等提出应用于3D点云数据的端到端深度学习框架VoxelNet，基于激光雷达扫描的3D数据进行目标类别检测及边界框预测。

针对第二个问题粒子排列不变性的表达，除了上面提到的几种点云处理框架中采用特定网络层进行排列不变性的表达外，还有一些工作也在处理排列不变性问题及输入数据大小不固定的情况，例如卷积网络中，对输入图像的尺寸并没有要求，有没有类似的可以处理可变粒子数目的结构。Guttenberg等[@Guttenberg:2016wsa]提出了一种类比卷积层的排列等变神经网络层。

## 3	方法

我们学习的目标是得到模拟场景中每一帧中每一个粒子在一下时刻的运动状态，即每一个粒子的加速度，我们将被预测粒子视作一个智能体（agent），构建预测器，建模在不同交互场景下智能体应该有的表现，针对每一帧的每一个粒子，我们的聚焦点也是通过场景内的所有粒子信息，提取不同尺度的特征，来建模这一个粒子的受力及约束条件。下面智能体（agent）指代建模预测加速度的那个粒子以区分同一帧中的其他粒子。

### 3.1	统一数据处理结构

上面我们提到，对于SPH的离散粒子处理几乎无人涉及，我们参考3D目标检测中点云数据的处理，在学习voxelnet的特征学习网络结构基础上，针对SPH模拟场景及离散粒子特性，提出能够处理不同场景、应对粒子数目变化的粒子分组结构。

#### 3.1.1	模拟空间三维网格划分（3D grid partition）

给定一个模拟空间$R=[x_{min}^R, x_{max}^R]\times [y_{min}^R, y_{max}^R]\times[z_{min}^R, z_{max}^R]$，$X,Y,Z$轴的范围分别标记为$W,H,D$，我们将空间$R$划分为大小相等3D网格，记单个网格空间$G=[x_{min}^G, x_{max}^G]\times [y_{min}^G, y_{max}^G]\times[z_{min}^G, z_{max}^G]$，假设每个网格的大小为$g_w,g_h,g_d$，那么整个3D网格空间的大小为$\hat W=W/g_w,\hat H=H/g_h,\hat D=D/g_d$，记为$\hat R=[0, \hat W^{\hat R}]\times [0, \hat H^{\hat R}]\times[0, \hat D^{\hat R}]$。



#### 3.1.2	粒子定位（particle localization）

确定好3D网格后，我们需要根据粒子的坐标将粒子定位到相应的3D网格内。我们需要注意粒子的分布在模拟空间内是稀疏的，同时在每个3D网格内，粒子的数目是可变的。考虑到不同模拟场景的粒子半径存在不同的可能，假定粒子半径范围$[r_{min},r_{max}]$，我们得到在3D网格内每一维度粒子的取值范围，从中取定固定值$(t_x,t_y,t_z)$,从而为每个3D网格内最大粒子数目取定值$T=t_x\times t_y\times t_z$,如果粒子数目大于T，则随机采样T个粒子，这样做的目的是在基本能够不丢失粒子信息前提下，一方面减少计算的存储空间，另一方面也增加了训练的变化。



​

### 3.2	排列不变性学习


对于SPH模拟的粒子数据而言，另一个需要重点考虑的问题是输入数据的排列不变性，即模型对于输入数据的不同排列顺序应该是无差异的。我们从两方面来看，一是3D网格空间$\hat R$位置信息，二是单个3D网格内粒子的输入顺序。最终我们会保留网格在$\hat R$内的空间信息，因而我们只需要关注3D网格内粒子排列不变性问题。通常而言，要保证排列不变性有三种方法[@Qi:2016vq]：1）对输入数据以某一规则进行排序；2）将输入数据以序列形式输入进RNN，并穷尽所有的排列组合可能性；3）使用简单的对称函数聚合所有粒子的信息。针对SPH方法的粒子数据而言，首先无法为数据找到合适的排序规则，其次对于高分辨率达模拟而言，粒子数据达到百万级，RNN学习如此多元素无序性的性能无法得到保证，因而我们采用聚合所有粒子信息的方式，具体而言，我们针对每个3D网格内的粒子信息先使用MLP进行反射变化，为了控制训练参数，在所有3D网格之间共享MLP参数，最后对每个网格内所有粒子的每一维度的特征都使用最大池化进行聚合，这一过程可以表达为：
$$
f(\{\vec x_1,\vec x_2,...,\vec x_n\}) \Rightarrow g(h_1(\vec x_1),h_2(\vec x_2),...,h_n(\vec x_n))\tag{1}
$$
其中$\vec x_n​$表示每个粒子携带的特征信息，$h_n​$表示MLP，特殊的这里采用的共享权值的MLP，$h_1=h_2=…=h_n​$,$g​$表示最大池化函数，特殊的这里采用2D卷积网络中的最大池化层。

### 3.3	粒子受力及约束条件建模

我们需要根据当前帧所有粒子的位置和速度来构建预测器，基于智能体的位置和速度预测它在下一帧的加速度，一方面我们希望预测器能够进行准确率较高的预测，另一方面我们也希望尽可能建模N-S方程中粒子的各个单项受力和约束条件以使预测能够得到物理控制方程的解释。

#### 3.3.1	SPH方法物理描述

<!--我觉得从原始N-S方程开始说明可以让读者整个演变历程，如果显得无关且冗余，那就直接从SPH形式的N-S开始-->

在SPH方法中，流体是以拉格朗日视角进行观察的，Navier-Stokes方程可以表达为：
$$
\rho \cfrac{D\vec{u}}{Dt}=-\nabla p+\mu\nabla^2\vec{v}+ \sigma\nabla^2\vec{x} + \vec{f} \tag{2}
$$
在介绍部分，我们在概念上提到了SPH方法，现在来看SPH方法的数学表达，空间中任意一点的物理状态都可以表示为使用恰当光滑核函数的分离粒子的状态插值来表示。粒子$\vec{x}$的属性$A(\vec{x})$可以用它的邻居粒子$X$近似表示：
$$
A(\vec{x})=\sum_{j\in X}\cfrac{m_jA_j}{\rho_j}W(\vec{x}-\vec{x}_j)\tag{3}
$$
粘性力、表面张力及使用理想气体状态方程时压强可近似为:
$$
\begin{split}a_i^{viso}=\cfrac{\mu}{\rho_0}\sum_j(\vec{v}_j-\vec{v}_i)\nabla^2W(\vec{x}_j-\vec{x}_i)\\ 
a_i^{ten}=\cfrac{\sigma}{\rho_0}\sum_j(\vec{x}_j-\vec{x}_i)\nabla^2W(\vec{x}_j-\vec{x}_i)\\
a_i^{pres}=-\cfrac{k}{\rho_0}\sum_jm_j\nabla W(\vec{x}_j-\vec{x}_i)
\end{split}\tag{4}
$$
可以看到，在SPH方法中，光滑核函数的作用是智能体（agent）周边的粒子对其作用的权重，可以用一定复杂度的网络结构来近似，那么另一个亟待解决的问题是每一帧的所有粒子应该携带哪些信息作为输入。在特征编码层我们将会详细说明如何依次构建网络建模智能体与周边粒子交互的各个分力和约束条件。

#### 3.3.2	3D网格特征编码

3D网格特征编码层参考voxelnet[@Zhou:2017vn]的VFE层和pointnet[@Qi:2016vq]的transformnet进行设计，但是与原设计不同的是，所有3D网格信息都需要用来共同预测智能体的加速度，因而不能将3D网格作为分离的独立个体进行考虑，结合光滑核函数的特性，添加模拟场景中的所有粒子相对于智能体的位移矢量作为粒子特征的3个维度，我们标记智能体的坐标为$(c_x,c_y,c_z)$，那么单个3D网格携带的信息可以表达为：
$$
G_{info}=\{\vec p_i=[x_i,y_i,z_i,{v_x}_i,{v_y}_i,{v_z}_i,isSolid,index,x_i-c_x,y_i-c_y,z_i-c_z] ^T\in \mathbb R^{11}\}_{i=1...t}\tag{5}
$$

然后，我们采用式$(1)$对每一个3D网格构建排列不变性，我们称之为排列不变层（ Permutation-Invariance layer,PIL）,每一个PIL由三层共享权值的MLP和一个最大池化层（Max Pooling Layer）构成。在PIL的三层MLP仿射变换后，我们从粒子的输入信息$\vec p_i$得到每个粒子的逐点特征$\vec f_i\in \mathbb R^m$，在最大池化层后将得到局部聚合特征$\widetilde f\in \mathbb R^m$,最后得到粒子的排列不变特征$f_{i_{out}}=[\vec f_i^T,\widetilde f^T]^T\in \mathbb R^{2m}$,最终得到的3D网格排列不变特征可以表达为：
$$
G_{info\_out}=\{f_{i_{out}}=[\vec f_i^T,\widetilde f^T]^T\in \mathbb R^{2m}\}_{i=1...t}\tag{6}
$$

#### 3.3.3 	智能体特征空间构建

之前我们提到，我们的目标是根据场景中所有粒子的特征，为智能体在不同交互场景下的加速度构建预测器，那么现在就可以转化为在新的仿真网格特征空间$\hat R_{info}=\{{{G_{info\_out}}_i}_{}\}_{i=1,2…K}$进行预测器构建。我们将会构建一个5D张量$T_{\hat R_{info}}$来表达$\hat R_{info}$:
$$
T_{\hat R_{info}} = [B,  \hat W^{\hat R},  \hat H^{\hat R},  \hat D^{\hat R}, 2m]\tag{7}
$$
式$(7)$中B代表batch_size,代表智能体的个数。每一个3D网格都可以根据三维空间坐标在特征空间$T_{\hat R_{info}} $得到表达。

#### 3.3.4	不同尺度N-S方程力和约束特征

在特征空间$T_{\hat R_{info}} $后，我们可以利用卷积神经网络多层次叠加可获取不同尺度特征的特性，利用全卷积进行特征提取，一方面提取场景交互中不同尺度的力和约束，另一方面减少网络中训练参数。

首先进行3D卷积运算以进行信息压缩，将特征空间压缩到2D，此后在主网络进行卷积运算的同时，分别进行三次下采样，下采样后与主网络同步进行卷积运算，主网络建模其他的力和约束，下采样的三个网络分别建模粘性力，表面张力和压强力，从而得到4个网络的输出$conv_1(T_{\hat R_{info}}),conv_2(T_{\hat R_{info}}),conv_3(T_{\hat R_{info}}),conv_4(T_{\hat R_{info}})$,最终预测器的加速度可以表达为：
$$
\hat {\vec a}_i = REG(conv_1(T_{\hat R_{info}}),conv_2(T_{\hat R_{info}}),conv_3(T_{\hat R_{info}}),conv_4(T_{\hat R_{info}}))\tag{8}
$$
不同力和约束的实现细节在3.5部分详述。



### 3.4	损失函数

记$\{\hat {\vec a}_i\}_{i=1,2…N}$为每个智能体的预测加速度，$\{{\vec a_i}\}_{i=1,2…N}$为训练数据集真实加速度，损失函数L可以表达为：
$$
L = \cfrac{1}{N}\sum_{i=1}^N({\hat {\vec a}_i - \vec a_i})^2\tag{9}
$$

### 3.5	训练详情

针对具体实验方法的说明具体数据及网络结构上的细节操作。


## 4	实验

实验数据来源

实验结果

对比

## 5	结论

目前的网络结构没有很好的保证流体的不可压缩性

## 参考文献