{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluidAINet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/datasets/simulation_data/water/1/particles_665.csv', '/data/datasets/simulation_data/water/1/particles_1504.csv']\n"
     ]
    }
   ],
   "source": [
    "%run -i utils/fluid_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i utils/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ScatterNd:0\", shape=(3, 40, 40, 50, 128), dtype=float32)\n",
      "[<tf.Tensor 'gpu_0/MiddleAndRPN_/output/BiasAdd_1:0' shape=(?, 3) dtype=float32>]\n",
      "Tensor(\"gpu_0/ScatterNd:0\", shape=(2, 40, 40, 50, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "%run -i utils/model_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1600, 64, 12)\n",
      "(?, 1600, 64, 1)\n",
      "(?, 40, 40, 64)\n",
      "temp_conv shape: Tensor(\"MiddleAndRPN_/concat:0\", shape=(?, 20, 20, 768), dtype=float32)\n",
      "r_map shape: Tensor(\"MiddleAndRPN_/conv21/BiasAdd:0\", shape=(?, 20, 20, 3), dtype=float32)\n",
      "final_features shape: (?, 1200)\n",
      "pred:\n",
      " Tensor(\"MiddleAndRPN_/output/BiasAdd:0\", shape=(?, 3), dtype=float32)\n",
      "********************************\n",
      "Tensor(\"MiddleAndRPN_/Sum:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "%run -i model/rpn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/data/datasets/simulation_data'\n",
    "train_dir = os.path.join(data_dir, 'water')\n",
    "TRAIN_FILES = get_all_frames(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6602"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(TRAIN_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n"
     ]
    }
   ],
   "source": [
    "singel_batch = None\n",
    "for batch in iterate_data(train_dir, batch_size=batch_size):\n",
    "    singel_batch = batch \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singel_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9428, 64, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ret = (\n",
    "    np.array(vox_labels),\n",
    "    np.array(vox_feature),\n",
    "    np.array(vox_number),\n",
    "    np.array(vox_coordinate),\n",
    "    np.array(vox_centroid),\n",
    "    np.array(vox_k_dynamic)\n",
    ")\n",
    "\"\"\"\n",
    "singel_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存目前的模型，并加载在新的graph中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_checkpoint:\n",
      " /data/deeplearning/FluidAiNet/save_model/default/checkpoint-00000111\n",
      "absolute_model_folder:\n",
      " /data/deeplearning/FluidAiNet/save_model/default\n",
      "output_graph:\n",
      " /data/deeplearning/FluidAiNet/save_model/default/../frozen_model/frozen_model.pb\n",
      "INFO:tensorflow:Restoring parameters from /data/deeplearning/FluidAiNet/save_model/default/checkpoint-00000111\n",
      "INFO:tensorflow:Froze 52 variables.\n",
      "Converted 52 variables to const ops.\n",
      "482 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "# # freeze model\n",
    "model_dir = \"/data/deeplearning/FluidAiNet/save_model/default\"\n",
    "try:\n",
    "    freeze_graph(model_dir, output_node_names=\"gpu_0/screen_size,concat_129,gpu_0/MiddleAndRPN_/output/BiasAdd\")\n",
    "except Exception as e:\n",
    "    print(\"output_node_names not find in the graph:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# graph model file path\n",
    "model_dir = \"/data/deeplearning/FluidAiNet/save_model/default\"\n",
    "frozen_model_filename = os.path.join(model_dir, \"../frozen_model/frozen_model.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ScatterNd:0\", shape=(50, 40, 40, 50, 128), dtype=float32)\n",
      "[<tf.Tensor 'gpu_0/MiddleAndRPN_/output/BiasAdd_1:0' shape=(?, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# load graph\n",
    "# graph = load_graph(frozen_model_filename)\n",
    "graph, acceleration = load_graph_with_input_map(frozen_model_filename, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full Flow\n",
    "1. create new scatter_nd with new batch size\n",
    "2. get graph and acceleration by load_graph_with_input_map\n",
    "3. get tensor in graph by tensor name(pay a attention tensor should be in same graph)\n",
    "4. load particles in a frame\n",
    "\"\"\"\n",
    "def fluidnet_predict(frozen_model_filename, batch_size=1, singel_batch=None):\n",
    "    graph, acceleration = load_graph_with_input_map(frozen_model_filename, batch_size=batch_size)\n",
    "    \"\"\"\n",
    "    node name\n",
    "    \"\"\"\n",
    "    'gpu_0/feature_0'\n",
    "    'gpu_0/k_dynamics'\n",
    "    'gpu_0/centroid'\n",
    "    'gpu_0/coordinate'\n",
    "    screen_size = graph.get_tensor_by_name('gpu_0/screen_size:0')\n",
    "    feature = graph.get_tensor_by_name('gpu_0/feature:0')\n",
    "    part_feature = graph.get_tensor_by_name('gpu_0/part_feature:0')\n",
    "    concat_feature = graph.get_tensor_by_name('concat_129:0')\n",
    "    # accelaration = graph.get_tensor_by_name(\"gpu_0/MiddleAndRPN_/output/BiasAdd:0\")\n",
    "    centroid = graph.get_tensor_by_name(\"gpu_0/centroid:0\")\n",
    "    k_dynamics = graph.get_tensor_by_name(\"gpu_0/k_dynamics:0\")\n",
    "    coordinate = graph.get_tensor_by_name(\"gpu_0/coordinate:0\")\n",
    "    phase = graph.get_tensor_by_name(\"phase:0\")\n",
    "    scatter_nd = graph.get_tensor_by_name('gpu_0/ScatterNd:0')\n",
    "    voxelwise = graph.get_tensor_by_name(\"gpu_0/Max_1:0\")\n",
    "    # 需要feed新的变量\n",
    "    phase_1 = graph.get_tensor_by_name(\"phase_1:0\")\n",
    "    \n",
    "    \"\"\"\n",
    "    generate fake data with batch_size = 3\n",
    "    \"\"\"\n",
    "    def sample_Z_3D(m, n, k):\n",
    "        return np.random.uniform(-8., 8., size=[m, n, k])\n",
    "    def sample_Z_2D(m, n):\n",
    "        return np.random.uniform(-8., 8., size=[m, n])\n",
    "    \n",
    "    feature_ = sample_Z_3D(7, 64, 8)\n",
    "    k_dynamics_ = np.array([4, 1, 2])\n",
    "    coordinate_ = np.array([[0, 1, 2, 3],\n",
    "               [0, 1, 2, 3],\n",
    "               [0, 1, 2, 3],\n",
    "               [0, 1, 2, 3],\n",
    "               [1, 1, 2, 3],\n",
    "               [1, 1, 2, 3],\n",
    "               [2, 1, 2, 3],  ])\n",
    "    centroid_ = np.array([[0.4, 0.4, 0.4], [0.3, 0.3, 0.3], [0.3, 0.3, 0.3]])\n",
    "    \n",
    "    # predict\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        input_dict = dict()\n",
    "        input_dict[phase] = False\n",
    "        input_dict[phase_1] = False\n",
    "        screen_size_eval = screen_size.eval(session=sess, feed_dict={screen_size: batch_size})\n",
    "        concat_feature_all = []\n",
    "        count = 0\n",
    "        # 如果要并行的话肯定还是要处理的，\n",
    "        print(\"screen_size_eval:\\n\", screen_size_eval)\n",
    "        for screen in range(screen_size_eval):\n",
    "            k = k_dynamics[screen]\n",
    "            concat_feature_all.append(tf.concat([part_feature[count: count+k],part_feature[count: count+k,:,:3] -centroid[screen]],axis=2))\n",
    "\n",
    "            count += k\n",
    "        concat_feature_all = tf.concat(concat_feature_all, axis=0)\n",
    "        \"\"\"\n",
    "        what if I use fake data\n",
    "        \"\"\"\n",
    "        option = 2\n",
    "        if option == 2 and singel_batch is None:\n",
    "            print(\"single_batch can't be None\")\n",
    "            return \n",
    "        if option == 1:\n",
    "            input_dict[part_feature] = feature_\n",
    "            input_dict[k_dynamics] = k_dynamics_\n",
    "            input_dict[centroid] = centroid_\n",
    "            concat_feature_eval = sess.run(concat_feature_all, input_dict)\n",
    "            input_dict[feature] = concat_feature_eval\n",
    "            input_dict[coordinate] = coordinate_\n",
    "        #     input_dict[coordinate] = singel_batch[0]\n",
    "            accelaration_eval = sess.run(acceleration[0], feed_dict=input_dict)\n",
    "        else:\n",
    "            input_dict[part_feature] = singel_batch[1][0]\n",
    "            input_dict[k_dynamics] = singel_batch[5][0]\n",
    "            input_dict[centroid] = singel_batch[4][0]\n",
    "            concat_feature_eval = sess.run(concat_feature_all, input_dict)\n",
    "            input_dict[feature] = concat_feature_eval\n",
    "            input_dict[coordinate] = singel_batch[3][0]\n",
    "            input_dict[phase] = False\n",
    "        #     input_dict[coordinate] = singel_batch[0]\n",
    "            accelaration_eval = sess.run(acceleration[0], feed_dict=input_dict)\n",
    "            \n",
    "        return accelaration_eval\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ScatterNd:0\", shape=(10, 40, 40, 50, 128), dtype=float32)\n",
      "[<tf.Tensor 'gpu_0/MiddleAndRPN_/output/BiasAdd_1:0' shape=(?, 3) dtype=float32>]\n",
      "screen_size_eval:\n",
      " 10\n"
     ]
    }
   ],
   "source": [
    "accelaration_eval = fluidnet_predict(frozen_model_filename, batch_size, singel_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelaration_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.49843097,   0.13586789, -23.93910027],\n",
       "       [ -1.49753499,   0.1387561 , -24.00110435],\n",
       "       [ -1.49596071,   0.14156944, -24.0581913 ],\n",
       "       [ -1.49420166,   0.14477903, -24.1126194 ],\n",
       "       [ -1.49289441,   0.14809364, -24.16362953],\n",
       "       [ -1.49142098,   0.15163022, -24.21033287],\n",
       "       [ -1.48990059,   0.15444452, -24.25127411],\n",
       "       [ -1.48896194,   0.15668255, -24.28781319],\n",
       "       [ -1.48917985,   0.15904588, -24.31986809],\n",
       "       [ -1.48916245,   0.16088814, -24.34318733]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelaration_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ScatterNd:0\", shape=(3, 40, 40, 50, 128), dtype=float32)\n",
      "[<tf.Tensor 'gpu_0/MiddleAndRPN_/conv3/Conv3D_1:0' shape=(3, 40, 40, 12, 64) dtype=float32>]\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f3aac256908>\n"
     ]
    }
   ],
   "source": [
    "prefix = ''\n",
    "with tf.gfile.GFile(frozen_model_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "# Then, we import the graph_def into a new Graph and returns it\n",
    "graph_out = graph\n",
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def, name=prefix)\n",
    "    coordinate = graph.get_tensor_by_name(\"gpu_0/coordinate:0\")\n",
    "    voxelwise = graph.get_tensor_by_name(\"gpu_0/Max_1:0\")\n",
    "    scatter_nd = graph.get_tensor_by_name(\"gpu_0/ScatterNd:0\")\n",
    "    # holder = tf.placeholder(tf.float32,shape=(3, 40, 40, 50, 1))\n",
    "    new_scatter_nd = tf.scatter_nd(coordinate, voxelwise, shape=[batch_size, 40, 40, 50, 128])\n",
    "    print(new_scatter_nd)\n",
    "    conv3D = graph.get_tensor_by_name('gpu_0/MiddleAndRPN_/conv1/Conv3D:0')\n",
    "    # print(conv3D)\n",
    "    # conv3D.input = new_scatter_nd\n",
    "    # print(conv3D.input.shape)\n",
    "    # graph.graph_place()\n",
    "    # The name var will prefix every op/nodes in your graph\n",
    "    # Since we load everything in a new graph, this is not needed\n",
    "#with tf.Graph().as_default() as graph:\n",
    "    #scatter_nd = graph.get_tensor_by_name('gpu_0/ScatterNd:0')\n",
    "    # saver = tf.train.import_meta_graph(graph_def, name=prefix, input_map={'gpu_0/ScatterNd': holder})\n",
    "    #z = tf.import_graph_def(graph_def, name=prefix, input_map={'gpu_0/ScatterNd:0': new_scatter_nd},return_elements=[\"gpu_0/MiddleAndRPN_/conv1/Conv3D:0\"])\n",
    "    accerlation = tf.import_graph_def(graph_def, name=prefix, input_map={'gpu_0/ScatterNd:0': new_scatter_nd}, return_elements=[\"gpu_0/MiddleAndRPN_/conv3/Conv3D:0\"])\n",
    "    print(accerlation)\n",
    "    graph_out = graph\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_out.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gpu_0/Max_1:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3d_1 = graph.get_tensor_by_name('gpu_0/MiddleAndRPN_/conv1/Conv3D:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gpu_0/MiddleAndRPN_/conv1/Conv3D:0' shape=(4, 40, 40, 25, 64) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# cheack nodes in gaph\n",
    "with tf.Session(graph=graph) as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    print(all_nodes(\"loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "node name\n",
    "\"\"\"\n",
    "'gpu_0/feature_0'\n",
    "'gpu_0/k_dynamics'\n",
    "'gpu_0/centroid'\n",
    "'gpu_0/coordinate'\n",
    "screen_size = graph.get_tensor_by_name('gpu_0/screen_size:0')\n",
    "feature = graph.get_tensor_by_name('gpu_0/feature:0')\n",
    "part_feature = graph.get_tensor_by_name('gpu_0/part_feature:0')\n",
    "concat_feature = graph.get_tensor_by_name('concat_129:0')\n",
    "# accelaration = graph.get_tensor_by_name(\"gpu_0/MiddleAndRPN_/output/BiasAdd:0\")\n",
    "centroid = graph.get_tensor_by_name(\"gpu_0/centroid:0\")\n",
    "k_dynamics = graph.get_tensor_by_name(\"gpu_0/k_dynamics:0\")\n",
    "coordinate = graph.get_tensor_by_name(\"gpu_0/coordinate:0\")\n",
    "phase = graph.get_tensor_by_name(\"phase:0\")\n",
    "scatter_nd = graph.get_tensor_by_name('gpu_0/ScatterNd:0')\n",
    "voxelwise = graph.get_tensor_by_name(\"gpu_0/Max_1:0\")\n",
    "# 需要feed新的变量\n",
    "phase_1 = graph.get_tensor_by_name(\"phase_1:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要feed新的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z_3D(m, n, k):\n",
    "    return np.random.uniform(-8., 8., size=[m, n, k])\n",
    "def sample_Z_2D(m, n):\n",
    "    return np.random.uniform(-8., 8., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ = sample_Z_3D(7, 64, 8)\n",
    "k_dynamics_ = np.array([4,1, 2])\n",
    "coordinate_ = np.array([[0, 1, 2, 3],\n",
    "               [0, 1, 2, 3],\n",
    "               [0, 1, 2, 3],\n",
    "               [0, 1, 2, 3],\n",
    "               [1, 1, 2, 3],\n",
    "               [1, 1, 2, 3],\n",
    "               [2, 1, 2, 3],  ])\n",
    "centroid_ = np.array([[0.4, 0.4, 0.4], [0.3, 0.3, 0.3], [0.3, 0.3, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(50), Dimension(128)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_nd.shape\n",
    "# scatter_nd.set_shape([batch_size, 40, 40, 50, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_size_eval:\n",
      " 16\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    input_dict = dict()\n",
    "    input_dict[phase] = False\n",
    "    input_dict[phase_1] = False\n",
    "    screen_size_eval = screen_size.eval(session=sess, feed_dict={screen_size: batch_size})\n",
    "    concat_feature_all = []\n",
    "    count = 0\n",
    "    # 如果要并行的话肯定还是要处理的，\n",
    "    print(\"screen_size_eval:\\n\", screen_size_eval)\n",
    "    for screen in range(screen_size_eval):\n",
    "        k = k_dynamics[screen]\n",
    "        concat_feature_all.append(tf.concat([part_feature[count: count+k],part_feature[count: count+k,:,:3] -centroid[screen]],axis=2))\n",
    "        \n",
    "        count += k\n",
    "    concat_feature_all = tf.concat(concat_feature_all, axis=0)\n",
    "    \"\"\"\n",
    "    what if I use fake data\n",
    "    \"\"\"\n",
    "    option = 2\n",
    "    if option == 1:\n",
    "        input_dict[part_feature] = feature_\n",
    "        input_dict[k_dynamics] = k_dynamics_\n",
    "        input_dict[centroid] = centroid_\n",
    "        concat_feature_eval = sess.run(concat_feature_all, input_dict)\n",
    "        input_dict[feature] = concat_feature_eval\n",
    "        input_dict[coordinate] = coordinate_\n",
    "    #     input_dict[coordinate] = singel_batch[0]\n",
    "        accelaration_eval = sess.run(accerlation[0], feed_dict=input_dict)\n",
    "    else:\n",
    "        input_dict[part_feature] = singel_batch[1][0]\n",
    "        input_dict[k_dynamics] = singel_batch[5][0]\n",
    "        input_dict[centroid] = singel_batch[4][0]\n",
    "        concat_feature_eval = sess.run(concat_feature_all, input_dict)\n",
    "        input_dict[feature] = concat_feature_eval\n",
    "        input_dict[coordinate] = singel_batch[3][0]\n",
    "        input_dict[phase] = False\n",
    "    #     input_dict[coordinate] = singel_batch[0]\n",
    "        accelaration_eval = sess.run(accerlation[0], feed_dict=input_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 64, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_feature_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [0, 1, 2, 3],\n",
       "       [0, 1, 2, 3],\n",
       "       [0, 1, 2, 3],\n",
       "       [1, 1, 2, 3],\n",
       "       [1, 1, 2, 3],\n",
       "       [2, 1, 2, 3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(singel_batch[3][0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelaration_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.49321055,   0.13378024, -23.83083534],\n",
       "       [ -1.49234414,   0.13667035, -23.89191246],\n",
       "       [ -1.4912684 ,   0.13916129, -23.94758606],\n",
       "       [ -1.48953366,   0.14206082, -24.00158882],\n",
       "       [ -1.48810554,   0.1451835 , -24.0526638 ],\n",
       "       [ -1.48659086,   0.1486482 , -24.0993824 ],\n",
       "       [ -1.48489404,   0.15184385, -24.14052391],\n",
       "       [ -1.48355079,   0.1541751 , -24.17666435],\n",
       "       [ -1.48274016,   0.15651435, -24.20915413],\n",
       "       [ -1.48259497,   0.15835136, -24.23295021],\n",
       "       [ -1.48106313,   0.16027337, -24.24737549],\n",
       "       [ -1.47982621,   0.16274863, -24.25875092],\n",
       "       [ -1.47952056,   0.16635114, -24.26746941],\n",
       "       [ -1.48024392,   0.16905516, -24.27392578],\n",
       "       [ -1.48338151,   0.17141372, -24.27762985],\n",
       "       [ -1.49085975,   0.17232627, -24.27821159]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelaration_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get all files including screens and frames\n",
    "\"\"\"\n",
    "BASE_DIR = '/data/datasets/simulation_data'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_frames(data_dir=DATA_DIR):\n",
    "    dirs = os.listdir(data_dir)\n",
    "    frames = []\n",
    "    for item in dirs:\n",
    "        screen_path = os.path.join(data_dir, item)\n",
    "        allfiles = os.listdir(screen_path)\n",
    "        frames.extend(map(lambda x:os.path.join(item, x), allfiles))\n",
    "    return map(lambda x:os.path.join(data_dir, x), frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = get_all_frames(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n"
     ]
    }
   ],
   "source": [
    "for f in TRAIN_FILES:\n",
    "    particles = load_data_file(f)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = particles.columns\n",
    "index = particles[particles[cols[7]]==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4528"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particles.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting FuildAINetTest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile FuildAINetTest.py\n",
    "\n",
    "import utils.fluid_loader as fl\n",
    "BASE_DIR = '/data/datasets/simulation_data'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'water')\n",
    "\n",
    "class TestFluid(object):\n",
    "    def __init__(self):\n",
    "        self.data_dir = DATA_DIR\n",
    "    def test_iter_data(self):\n",
    "        for item in fl.iterate_data(self.data_dir):\n",
    "            print(item)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    testf1 = TestFluid()\n",
    "    testf1.test_iter_data()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.fluid_loader' from '/data/deeplearning/FluidAiNet/utils/fluid_loader.py'>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluid\n",
      "(62032, 3)\n",
      "2357\n"
     ]
    }
   ],
   "source": [
    "import utils.fluid_loader as fl\n",
    "import imp\n",
    "imp.reload(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object iterate_data at 0x7f6a9a025888>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl.iterate_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i utils/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/datasets/simulation_data/water/1/particles_665.csv', '/data/datasets/simulation_data/water/1/particles_1504.csv']\n",
      "csv\n",
      "Fluid\n",
      "[[-1.      -1.       1.05335 ..., -8.21249  0.       0.     ]\n",
      " [-0.9     -1.       1.05335 ..., -8.21249  0.       0.     ]\n",
      " [-0.8     -1.       1.05335 ..., -8.21249  0.       0.     ]\n",
      " ..., \n",
      " [ 3.8      4.       3.95    ...,  0.       1.       0.     ]\n",
      " [ 3.9      4.       3.95    ...,  0.       1.       0.     ]\n",
      " [ 4.       4.       3.95    ...,  0.       1.       0.     ]]\n",
      "(62032, 3)\n",
      "2357\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EasyDict' object has no attribute 'VOXEL_POINT_FEATURE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/data/deeplearning/FluidAiNet/utils/preprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FILES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpointcloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FILES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvoxel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid_process_pointcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointcloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/deeplearning/FluidAiNet/utils/preprocess.py\u001b[0m in \u001b[0;36mfluid_process_pointcloud\u001b[0;34m(point_cloud, fluid_identification, cls)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# [K, T, 7] feature buffer as described in the paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfeature_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# position, velocity, isFluid, index, relative position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# build a reverse index for coordinate buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EasyDict' object has no attribute 'VOXEL_POINT_FEATURE'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "TRAIN_FILES = fl.create_train_files(BATCH_SIZE)\n",
    "print(TRAIN_FILES)\n",
    "pointcloud, _, _ = fl.load_data_label(TRAIN_FILES[0])\n",
    "voxel_index = fluid_process_pointcloud(pointcloud, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/data/deeplearning/FluidAiNet/config.py'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a -[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_p = np.array([1, 1])\n",
    "temp_p = np.lib.pad(temp_p, (1, 1), 'constant', constant_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddings = (np.array(temp_p)).repeat(2).reshape(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.uniform(-8., 8., size=[3, 40,40, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = tf.pad(input, paddings, \"CONSTANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Pad:0' shape=(3, 42, 42, 64) dtype=float64>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
