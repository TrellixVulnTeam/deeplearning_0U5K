{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_dir = '/data/datasets/kitti/objects/training'\n",
    "np.random.seed()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [2, 3], [3, 4], [4, 5]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: [x, x+1], [1, 2 ,3 ,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag ='0000'\n",
    "rgb = cv2.resize(cv2.imread(os.path.join(object_dir,\n",
    "                                         'image_2', tag +'/000000.png')), (cfg.IMAGE_WIDTH, cfg.IMAGE_HEIGHT))\n",
    "#rgb = cv2.imread( os.path.join(object_dir,'image_2', tag + '.png')  )\n",
    "lidar = np.fromfile(os.path.join(object_dir,\n",
    "                                 'velodyne', tag + '/000000.bin'), dtype=np.float32).reshape(-1, 4)\n",
    "label = np.array([line for line in open(os.path.join(\n",
    "    object_dir, 'label_2', tag + '.txt'), 'r').readlines()])  # (N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123397, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.71899986,   0.031     ,   0.977     ],\n",
       "       [ 18.05200005,   0.076     ,   0.81999999],\n",
       "       [ 18.02599907,   0.132     ,   0.81900001],\n",
       "       ..., \n",
       "       [  3.77699995,  -1.40900004,  -1.76400006],\n",
       "       [  3.7750001 ,  -1.39400005,  -1.75999999],\n",
       "       [  5.63399982,  -1.39499998,  -2.58999991]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 3, 2])\n",
    "a = a[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.31999999,   0.977     ,   0.031     ,  22.71899986],\n",
       "       [  0.46000001,   0.81999999,   0.076     ,  18.05200005],\n",
       "       [  0.23999999,   0.81900001,   0.132     ,  18.02599907],\n",
       "       ..., \n",
       "       [  0.        ,  -1.76400006,  -1.40900004,   3.77699995],\n",
       "       [  0.        ,  -1.75999999,  -1.39400005,   3.7750001 ],\n",
       "       [  0.        ,  -2.58999991,  -1.39499998,   5.63399982]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '-1',\n",
       " 'DontCare',\n",
       " '-1',\n",
       " '-1',\n",
       " '-10.000000',\n",
       " '219.310000',\n",
       " '188.490000',\n",
       " '245.500000',\n",
       " '218.560000',\n",
       " '-1000.000000',\n",
       " '-1000.000000',\n",
       " '-1000.000000',\n",
       " '-10.000000',\n",
       " '-1.000000',\n",
       " '-1.000000',\n",
       " '-1.000000\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10890756423091877380, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7317697332\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 741389361098257739\n",
       " physical_device_desc: \"device: 0, name: Quadro M5000, pci bus id: 0000:03:00.0, compute capability: 5.2\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "get_available_gpus()\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_fluid.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding:UTF-8 -*-\n",
    "\n",
    "# File Name : train.py\n",
    "# Purpose :\n",
    "# Creation Date : 09-12-2017\n",
    "# Last Modified : Fri 19 Jan 2018 10:38:47 AM CST\n",
    "# Created By : Jeasine Ma [jeasinema[at]gmail[dot]com]\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from itertools import count\n",
    "\n",
    "from config import cfg\n",
    "from model import RPN3D\n",
    "from utils.kitti_loader import KittiLoader\n",
    "from train_hook import check_if_should_pause\n",
    "\n",
    "parser = argparse.ArgumentParser(description='training')\n",
    "parser.add_argument('-i', '--max-epoch', type=int, nargs='?', default=10,\n",
    "                    help='max epoch')\n",
    "parser.add_argument('-n', '--tag', type=str, nargs='?', default='default',\n",
    "                    help='set log tag')\n",
    "parser.add_argument('-b', '--single-batch-size', type=int, nargs='?', default=1,\n",
    "                    help='set batch size for each gpu')\n",
    "parser.add_argument('-l', '--lr', type=float, nargs='?', default=0.001,\n",
    "                    help='set learning rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "dataset_dir = './data/object'\n",
    "log_dir = os.path.join('./log', args.tag)\n",
    "save_model_dir = os.path.join('./save_model', args.tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # TODO: split file support\n",
    "    with tf.Graph().as_default():\n",
    "        global save_model_dir\n",
    "        with KittiLoader(object_dir=os.path.join(dataset_dir, 'training'), queue_size=50, require_shuffle=True,\n",
    "                         is_testset=False, batch_size=args.single_batch_size * cfg.GPU_USE_COUNT, use_multi_process_num=8, multi_gpu_sum=cfg.GPU_USE_COUNT, aug=True) as train_loader, \\\n",
    "            KittiLoader(object_dir=os.path.join(dataset_dir, 'testing'), queue_size=50, require_shuffle=True,\n",
    "                        is_testset=False, batch_size=args.single_batch_size * cfg.GPU_USE_COUNT, use_multi_process_num=8, multi_gpu_sum=cfg.GPU_USE_COUNT, aug=False) as valid_loader:\n",
    "\n",
    "            gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=cfg.GPU_MEMORY_FRACTION,\n",
    "                                        visible_device_list=cfg.GPU_AVAILABLE,\n",
    "                                        allow_growth=True)\n",
    "            config = tf.ConfigProto(\n",
    "                gpu_options=gpu_options,\n",
    "                device_count={\n",
    "                    \"GPU\": cfg.GPU_USE_COUNT,\n",
    "                },\n",
    "                allow_soft_placement=True,\n",
    "            )\n",
    "            with tf.Session(config=config) as sess:\n",
    "                model = RPN3D(\n",
    "                    cls=cfg.DETECT_OBJ,\n",
    "                    single_batch_size=args.single_batch_size,\n",
    "                    learning_rate=args.lr,\n",
    "                    max_gradient_norm=5.0,\n",
    "                    is_train=True,\n",
    "                    alpha=1.5,\n",
    "                    beta=1,\n",
    "                    avail_gpus=cfg.GPU_AVAILABLE.split(',')\n",
    "                )\n",
    "                # param init/restore\n",
    "                if tf.train.get_checkpoint_state(save_model_dir):\n",
    "                    print(\"Reading model parameters from %s\" % save_model_dir)\n",
    "                    model.saver.restore(\n",
    "                        sess, tf.train.latest_checkpoint(save_model_dir))\n",
    "                else:\n",
    "                    print(\"Created model with fresh parameters.\")\n",
    "                    tf.global_variables_initializer().run()\n",
    "\n",
    "                # train and validate\n",
    "                iter_per_epoch = int(\n",
    "                    len(train_loader) / (args.single_batch_size * cfg.GPU_USE_COUNT))\n",
    "                is_summary, is_summary_image, is_validate = False, False, False\n",
    "\n",
    "                summary_interval = 5\n",
    "                summary_image_interval = 20\n",
    "                save_model_interval = int(iter_per_epoch / 3)\n",
    "                validate_interval = 60\n",
    "\n",
    "                summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "                while model.epoch.eval() < args.max_epoch:\n",
    "                    is_summary, is_summary_image, is_validate = False, False, False\n",
    "                    iter = model.global_step.eval()\n",
    "                    if not iter % summary_interval:\n",
    "                        is_summary = True\n",
    "                    if not iter % summary_image_interval:\n",
    "                        is_summary_image = True\n",
    "                    if not iter % save_model_interval:\n",
    "                        model.saver.save(sess, os.path.join(\n",
    "                            save_model_dir, 'checkpoint'), global_step=model.global_step)\n",
    "                    if not iter % validate_interval:\n",
    "                        is_validate = True\n",
    "                    if not iter % iter_per_epoch:\n",
    "                        sess.run(model.epoch_add_op)\n",
    "                        print('train {} epoch, total: {}'.format(\n",
    "                            model.epoch.eval(), args.max_epoch))\n",
    "\n",
    "                    ret = model.train_step(\n",
    "                        sess, train_loader.load(), train=True, summary=is_summary)\n",
    "                    print('train: {}/{} @ epoch:{}/{} loss: {} reg_loss: {} cls_loss: {} {}'.format(iter,\n",
    "                                                                                                    iter_per_epoch * args.max_epoch, model.epoch.eval(), args.max_epoch, ret[0], ret[1], ret[2], args.tag))\n",
    "\n",
    "                    if is_summary:\n",
    "                        summary_writer.add_summary(ret[-1], iter)\n",
    "\n",
    "                    if is_summary_image:\n",
    "                        ret = model.predict_step(\n",
    "                                sess, valid_loader.load(), summary=True)\n",
    "                        summary_writer.add_summary(ret[-1], iter)\n",
    "\n",
    "                    if is_validate:\n",
    "                        ret = model.validate_step(\n",
    "                                sess, valid_loader.load(), summary=True)\n",
    "                        summary_writer.add_summary(ret[-1], iter)\n",
    "\n",
    "                    if check_if_should_pause(args.tag):\n",
    "                        model.saver.save(sess, os.path.join(\n",
    "                            save_model_dir, 'checkpoint'), global_step=model.global_step)\n",
    "                        print('pause and save model @ {} steps:{}'.format(\n",
    "                            save_model_dir, model.global_step.eval()))\n",
    "                        sys.exit(0)\n",
    "\n",
    "                print('train done. total epoch:{} iter:{}'.format(\n",
    "                    model.epoch.eval(), model.global_step.eval()))\n",
    "\n",
    "                # finallly save model\n",
    "                model.saver.save(sess, os.path.join(\n",
    "                    save_model_dir, 'checkpoint'), global_step=model.global_step)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing standard.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile standard.py\n",
    "# input() reads a string with a line of input, stripping the '\\n' (newline) at the end.\n",
    "# This is all you need for most Kickstart problems.\n",
    "t = int(input())  # read a line with a single integer\n",
    "for i in range(1, t + 1):\n",
    "  n, m = [int(s) for s in input().split(\" \")]  # read a list of integers, 2 in this case\n",
    "  print(\"Case #{}: {} {}\".format(i, n + m, n * m))\n",
    "  # check out .format's specification for more formatting options\n",
    "\n",
    "  # input() reads a string with a line of input, stripping the '\\n' (newline) at the end.\n",
    "# This is all you need for most Kickstart problems.\n",
    "t = int(input())  # read a line with a single integer\n",
    "for i in range(1, t + 1):\n",
    "  n, m = [int(s) for s in input().split(\" \")]  # read a list of integers, 2 in this case\n",
    "  print(\"Case #{}: {} {}\".format(i, n + m, n * m))\n",
    "  # check out .format's specification for more formatting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/deeplearning/vision/VoxelNet-tensorflow\r\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/model.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding:UTF-8 -*-\n",
    "\n",
    "# File Name : model.py\n",
    "# Purpose :\n",
    "# Creation Date : 09-12-2017\n",
    "# Last Modified : Fri 05 Jan 2018 09:34:48 PM CST\n",
    "# Created By : Jeasine Ma [jeasinema[at]gmail[dot]com]\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from numba import jit\n",
    "\n",
    "from config import cfg\n",
    "from utils import *\n",
    "from model.group_pointcloud import FeatureNet\n",
    "from model.rpn import MiddleAndRPN\n",
    "\n",
    "\n",
    "class RPN3D(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 cls='Car',\n",
    "                 single_batch_size=2,  # batch_size_per_gpu\n",
    "                 learning_rate=0.001,\n",
    "                 max_gradient_norm=5.0,\n",
    "                 alpha=1.5,\n",
    "                 beta=1,\n",
    "                 is_train=True,\n",
    "                 avail_gpus=['0']):\n",
    "        # hyper parameters and status\n",
    "        self.cls = cls\n",
    "        self.single_batch_size = single_batch_size\n",
    "        self.learning_rate = tf.Variable(\n",
    "            float(learning_rate), trainable=False, dtype=tf.float32)\n",
    "        self.global_step = tf.Variable(1, trainable=False)\n",
    "        self.epoch = tf.Variable(0, trainable=False)\n",
    "        self.epoch_add_op = self.epoch.assign(self.epoch + 1)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.avail_gpus = avail_gpus\n",
    "\n",
    "        lr = tf.train.exponential_decay(\n",
    "            self.learning_rate, self.global_step, 10000, 0.96)\n",
    "\n",
    "        # build graph\n",
    "        # input placeholders\n",
    "        self.vox_feature = []\n",
    "        self.vox_number = []\n",
    "        self.vox_coordinate = []\n",
    "        self.targets = []\n",
    "        self.pos_equal_one = []\n",
    "        self.pos_equal_one_sum = []\n",
    "        self.pos_equal_one_for_reg = []\n",
    "        self.neg_equal_one = []\n",
    "        self.neg_equal_one_sum = []\n",
    "\n",
    "        self.delta_output = []\n",
    "        self.prob_output = []\n",
    "        self.opt = tf.train.AdamOptimizer(lr)\n",
    "        self.gradient_norm = []\n",
    "        self.tower_grads = []\n",
    "        with tf.variable_scope(tf.get_variable_scope()):\n",
    "            for idx, dev in enumerate(self.avail_gpus):\n",
    "                with tf.device('/gpu:{}'.format(dev)), tf.name_scope('gpu_{}'.format(dev)):\n",
    "                    # must use name scope here since we do not want to create new variables\n",
    "                    # graph\n",
    "                    feature = FeatureNet(\n",
    "                        training=is_train, batch_size=self.single_batch_size)\n",
    "                    rpn = MiddleAndRPN(\n",
    "                        input=feature.outputs, alpha=self.alpha, beta=self.beta, training=is_train)\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    # input\n",
    "                    self.vox_feature.append(feature.feature)\n",
    "                    self.vox_number.append(feature.number)\n",
    "                    self.vox_coordinate.append(feature.coordinate)\n",
    "                    self.targets.append(rpn.targets)\n",
    "                    self.pos_equal_one.append(rpn.pos_equal_one)\n",
    "                    self.pos_equal_one_sum.append(rpn.pos_equal_one_sum)\n",
    "                    self.pos_equal_one_for_reg.append(\n",
    "                        rpn.pos_equal_one_for_reg)\n",
    "                    self.neg_equal_one.append(rpn.neg_equal_one)\n",
    "                    self.neg_equal_one_sum.append(rpn.neg_equal_one_sum)\n",
    "                    # output\n",
    "                    feature_output = feature.outputs\n",
    "                    delta_output = rpn.delta_output\n",
    "                    prob_output = rpn.prob_output\n",
    "                    # loss and grad\n",
    "                    self.loss = rpn.loss\n",
    "                    self.reg_loss = rpn.reg_loss\n",
    "                    self.cls_loss = rpn.cls_loss\n",
    "                    self.params = tf.trainable_variables()\n",
    "                    gradients = tf.gradients(self.loss, self.params)\n",
    "                    clipped_gradients, gradient_norm = tf.clip_by_global_norm(\n",
    "                        gradients, max_gradient_norm)\n",
    "\n",
    "                    self.delta_output.append(delta_output)\n",
    "                    self.prob_output.append(prob_output)\n",
    "                    self.tower_grads.append(clipped_gradients)\n",
    "                    self.gradient_norm.append(gradient_norm)\n",
    "                    self.rpn_output_shape = rpn.output_shape\n",
    "\n",
    "        # loss and optimizer\n",
    "        # self.xxxloss is only the loss for the lowest tower\n",
    "        with tf.device('/gpu:{}'.format(self.avail_gpus[0])):\n",
    "            self.grads = average_gradients(self.tower_grads)\n",
    "            self.update = self.opt.apply_gradients(\n",
    "                zip(self.grads, self.params), global_step=self.global_step)\n",
    "            self.gradient_norm = tf.group(*self.gradient_norm)\n",
    "\n",
    "        self.delta_output = tf.concat(self.delta_output, axis=0)\n",
    "        self.prob_output = tf.concat(self.prob_output, axis=0)\n",
    "\n",
    "        self.anchors = cal_anchors()\n",
    "        # for predict and image summary\n",
    "        self.rgb = tf.placeholder(\n",
    "            tf.uint8, [None, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, 3])\n",
    "        self.bv = tf.placeholder(tf.uint8, [\n",
    "                                 None, cfg.BV_LOG_FACTOR * cfg.INPUT_HEIGHT, cfg.BV_LOG_FACTOR * cfg.INPUT_WIDTH, 3])\n",
    "        self.bv_heatmap = tf.placeholder(tf.uint8, [\n",
    "            None, cfg.BV_LOG_FACTOR * cfg.FEATURE_HEIGHT, cfg.BV_LOG_FACTOR * cfg.FEATURE_WIDTH, 3])\n",
    "        self.boxes2d = tf.placeholder(tf.float32, [None, 4])\n",
    "        self.boxes2d_scores = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "        # NMS(2D)\n",
    "        with tf.device('/gpu:{}'.format(self.avail_gpus[0])):\n",
    "            self.box2d_ind_after_nms = tf.image.non_max_suppression(\n",
    "                self.boxes2d, self.boxes2d_scores, max_output_size=cfg.RPN_NMS_POST_TOPK, iou_threshold=cfg.RPN_NMS_THRESH)\n",
    "\n",
    "        # summary and saver\n",
    "        self.saver = tf.train.Saver(write_version=tf.train.SaverDef.V2,\n",
    "                                    max_to_keep=10, pad_step_number=True, keep_checkpoint_every_n_hours=1.0)\n",
    "\n",
    "        self.train_summary = tf.summary.merge([\n",
    "            tf.summary.scalar('train/loss', self.loss),\n",
    "            tf.summary.scalar('train/reg_loss', self.reg_loss),\n",
    "            tf.summary.scalar('train/cls_loss', self.cls_loss),\n",
    "            *[tf.summary.histogram(each.name, each) for each in self.params]\n",
    "        ])\n",
    "\n",
    "        self.validate_summary = tf.summary.merge([\n",
    "            tf.summary.scalar('validate/loss', self.loss),\n",
    "            tf.summary.scalar('validate/reg_loss', self.reg_loss),\n",
    "            tf.summary.scalar('validate/cls_loss', self.cls_loss)\n",
    "        ])\n",
    "\n",
    "        # TODO: bird_view_summary and front_view_summary\n",
    "\n",
    "        self.predict_summary = tf.summary.merge([\n",
    "            tf.summary.image('predict/bird_view_lidar', self.bv),\n",
    "            tf.summary.image('predict/bird_view_heatmap', self.bv_heatmap),\n",
    "            tf.summary.image('predict/front_view_rgb', self.rgb),\n",
    "        ])\n",
    "\n",
    "    def train_step(self, session, data, train=False, summary=False):\n",
    "        # input:\n",
    "        #     (N) tag\n",
    "        #     (N, N') label\n",
    "        #     vox_feature\n",
    "        #     vox_number\n",
    "        #     vox_coordinate\n",
    "        tag = data[0]\n",
    "        label = data[1]\n",
    "        vox_feature = data[2]\n",
    "        vox_number = data[3]\n",
    "        vox_coordinate = data[4]\n",
    "        print('train', tag)\n",
    "        pos_equal_one, neg_equal_one, targets = cal_rpn_target(\n",
    "            label, self.rpn_output_shape, self.anchors, cls=cfg.DETECT_OBJ, coordinate='lidar')\n",
    "        pos_equal_one_for_reg = np.concatenate(\n",
    "            [np.tile(pos_equal_one[..., [0]], 7), np.tile(pos_equal_one[..., [1]], 7)], axis=-1)\n",
    "        pos_equal_one_sum = np.clip(np.sum(pos_equal_one, axis=(\n",
    "            1, 2, 3)).reshape(-1, 1, 1, 1), a_min=1, a_max=None)\n",
    "        neg_equal_one_sum = np.clip(np.sum(neg_equal_one, axis=(\n",
    "            1, 2, 3)).reshape(-1, 1, 1, 1), a_min=1, a_max=None)\n",
    "\n",
    "        input_feed = {}\n",
    "        for idx in range(len(self.avail_gpus)):\n",
    "            input_feed[self.vox_feature[idx]] = vox_feature[idx]\n",
    "            input_feed[self.vox_number[idx]] = vox_number[idx]\n",
    "            input_feed[self.vox_coordinate[idx]] = vox_coordinate[idx]\n",
    "            input_feed[self.targets[idx]] = targets[idx *\n",
    "                                                    self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.pos_equal_one[idx]] = pos_equal_one[idx *\n",
    "                                                                self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.pos_equal_one_sum[idx]] = pos_equal_one_sum[idx *\n",
    "                                                                        self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.pos_equal_one_for_reg[idx]] = pos_equal_one_for_reg[idx *\n",
    "                                                                                self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.neg_equal_one[idx]] = neg_equal_one[idx *\n",
    "                                                                self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.neg_equal_one_sum[idx]] = neg_equal_one_sum[idx *\n",
    "                                                                        self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "        if train:\n",
    "            output_feed = [self.loss, self.reg_loss,\n",
    "                           self.cls_loss, self.gradient_norm, self.update]\n",
    "        else:\n",
    "            output_feed = [self.loss, self.reg_loss, self.cls_loss]\n",
    "        if summary:\n",
    "            output_feed.append(self.train_summary)\n",
    "        # TODO: multi-gpu support for test and predict step\n",
    "        return session.run(output_feed, input_feed)\n",
    "\n",
    "    def validate_step(self, session, data, summary=False):\n",
    "        # input:\n",
    "        #     (N) tag\n",
    "        #     (N, N') label\n",
    "        #     vox_feature\n",
    "        #     vox_number\n",
    "        #     vox_coordinate\n",
    "        tag = data[0]\n",
    "        label = data[1]\n",
    "        vox_feature = data[2]\n",
    "        vox_number = data[3]\n",
    "        vox_coordinate = data[4]\n",
    "        print('valid', tag)\n",
    "        pos_equal_one, neg_equal_one, targets = cal_rpn_target(\n",
    "            label, self.rpn_output_shape, self.anchors)\n",
    "        pos_equal_one_for_reg = np.concatenate(\n",
    "            [np.tile(pos_equal_one[..., [0]], 7), np.tile(pos_equal_one[..., [1]], 7)], axis=-1)\n",
    "        pos_equal_one_sum = np.clip(np.sum(pos_equal_one, axis=(\n",
    "            1, 2, 3)).reshape(-1, 1, 1, 1), a_min=1, a_max=None)\n",
    "        neg_equal_one_sum = np.clip(np.sum(neg_equal_one, axis=(\n",
    "            1, 2, 3)).reshape(-1, 1, 1, 1), a_min=1, a_max=None)\n",
    "\n",
    "        input_feed = {}\n",
    "        for idx in range(len(self.avail_gpus)):\n",
    "            input_feed[self.vox_feature[idx]] = vox_feature[idx]\n",
    "            input_feed[self.vox_number[idx]] = vox_number[idx]\n",
    "            input_feed[self.vox_coordinate[idx]] = vox_coordinate[idx]\n",
    "            input_feed[self.targets[idx]] = targets[idx *\n",
    "                                                    self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.pos_equal_one[idx]] = pos_equal_one[idx *\n",
    "                                                                self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.pos_equal_one_sum[idx]] = pos_equal_one_sum[idx *\n",
    "                                                                        self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.pos_equal_one_for_reg[idx]] = pos_equal_one_for_reg[idx *\n",
    "                                                                                self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.neg_equal_one[idx]] = neg_equal_one[idx *\n",
    "                                                                self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "            input_feed[self.neg_equal_one_sum[idx]] = neg_equal_one_sum[idx *\n",
    "                                                                        self.single_batch_size:(idx + 1) * self.single_batch_size]\n",
    "\n",
    "        output_feed = [self.loss, self.reg_loss, self.cls_loss]\n",
    "        if summary:\n",
    "            output_feed.append(self.validate_summary)\n",
    "        return session.run(output_feed, input_feed)\n",
    "\n",
    "    def predict_step(self, session, data, summary=False):\n",
    "        # input:\n",
    "        #     (N) tag\n",
    "        #     (N, N') label(can be empty)\n",
    "        #     vox_feature\n",
    "        #     vox_number\n",
    "        #     vox_coordinate\n",
    "        #     img (N, w, l, 3)\n",
    "        #     lidar (N, N', 4)\n",
    "        # output: A, B, C\n",
    "        #     A: (N) tag\n",
    "        #     B: (N, N') (class, x, y, z, h, w, l, rz, score)\n",
    "        #     C; summary(optional)\n",
    "        tag = data[0]\n",
    "        label = data[1]\n",
    "        vox_feature = data[2]\n",
    "        vox_number = data[3]\n",
    "        vox_coordinate = data[4]\n",
    "        img = data[5]\n",
    "        lidar = data[6]\n",
    "\n",
    "        if summary:\n",
    "            batch_gt_boxes3d = label_to_gt_box3d(\n",
    "                label, cls=self.cls, coordinate='lidar')\n",
    "        print('predict', tag)\n",
    "        input_feed = {}\n",
    "        for idx in range(len(self.avail_gpus)):\n",
    "            input_feed[self.vox_feature[idx]] = vox_feature[idx]\n",
    "            input_feed[self.vox_number[idx]] = vox_number[idx]\n",
    "            input_feed[self.vox_coordinate[idx]] = vox_coordinate[idx]\n",
    "\n",
    "        output_feed = [self.prob_output, self.delta_output]\n",
    "        probs, deltas = session.run(output_feed, input_feed)\n",
    "        # BOTTLENECK\n",
    "        batch_boxes3d = delta_to_boxes3d(\n",
    "            deltas, self.anchors, coordinate='lidar')\n",
    "        batch_boxes2d = batch_boxes3d[:, :, [0, 1, 4, 5, 6]]\n",
    "        batch_probs = probs.reshape(\n",
    "            (len(self.avail_gpus) * self.single_batch_size, -1))\n",
    "        # NMS\n",
    "        ret_box3d = []\n",
    "        ret_score = []\n",
    "        for batch_id in range(len(self.avail_gpus) * self.single_batch_size):\n",
    "            # remove box with low score\n",
    "            ind = np.where(batch_probs[batch_id, :] >= cfg.RPN_SCORE_THRESH)[0]\n",
    "            tmp_boxes3d = batch_boxes3d[batch_id, ind, ...]\n",
    "            tmp_boxes2d = batch_boxes2d[batch_id, ind, ...]\n",
    "            tmp_scores = batch_probs[batch_id, ind]\n",
    "\n",
    "            # TODO: if possible, use rotate NMS\n",
    "            boxes2d = corner_to_standup_box2d(\n",
    "                center_to_corner_box2d(tmp_boxes2d, coordinate='lidar'))\n",
    "            ind = session.run(self.box2d_ind_after_nms, {\n",
    "                self.boxes2d: boxes2d,\n",
    "                self.boxes2d_scores: tmp_scores\n",
    "            })\n",
    "            tmp_boxes3d = tmp_boxes3d[ind, ...]\n",
    "            tmp_scores = tmp_scores[ind]\n",
    "            ret_box3d.append(tmp_boxes3d)\n",
    "            ret_score.append(tmp_scores)\n",
    "\n",
    "        ret_box3d_score = []\n",
    "        for boxes3d, scores in zip(ret_box3d, ret_score):\n",
    "            ret_box3d_score.append(np.concatenate([np.tile(self.cls, len(boxes3d))[:, np.newaxis],\n",
    "                                                   boxes3d, scores[:, np.newaxis]], axis=-1))\n",
    "\n",
    "        if summary:\n",
    "            # only summry 1 in a batch\n",
    "            front_image = draw_lidar_box3d_on_image(img[0], ret_box3d[0], ret_score[0],\n",
    "                                                    batch_gt_boxes3d[0])\n",
    "            bird_view = lidar_to_bird_view_img(\n",
    "                lidar[0], factor=cfg.BV_LOG_FACTOR)\n",
    "            bird_view = draw_lidar_box3d_on_birdview(bird_view, ret_box3d[0], ret_score[0],\n",
    "                                                     batch_gt_boxes3d[0], factor=cfg.BV_LOG_FACTOR)\n",
    "            heatmap = colorize(probs[0, ...], cfg.BV_LOG_FACTOR)\n",
    "            ret_summary = session.run(self.predict_summary, {\n",
    "                self.rgb: front_image[np.newaxis, ...],\n",
    "                self.bv: bird_view[np.newaxis, ...],\n",
    "                self.bv_heatmap: heatmap[np.newaxis, ...]\n",
    "            })\n",
    "\n",
    "            return tag, ret_box3d_score, ret_summary\n",
    "\n",
    "        return tag, ret_box3d_score\n",
    "\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    # ref:\n",
    "    # https://github.com/tensorflow/models/blob/6db9f0282e2ab12795628de6200670892a8ad6ba/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L103\n",
    "    # but only contains grads, no vars\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        grad_and_var = grad\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile  model/group_pointcloud.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from config import cfg\n",
    "\n",
    "\n",
    "class VFELayer(object):\n",
    "\n",
    "    def __init__(self, out_channels, name):\n",
    "        super(VFELayer, self).__init__()\n",
    "        self.units = int(out_channels / 2)\n",
    "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.dense = tf.layers.Dense(\n",
    "                self.units, tf.nn.relu, name='dense', _reuse=tf.AUTO_REUSE, _scope=scope)\n",
    "            self.batch_norm = tf.layers.BatchNormalization(\n",
    "                name='batch_norm', fused=True, _reuse=tf.AUTO_REUSE, _scope=scope)\n",
    "\n",
    "    def apply(self, inputs, mask, training):\n",
    "        # [K, T, 7] tensordot [7, units] = [K, T, units]\n",
    "        pointwise = self.batch_norm.apply(self.dense.apply(inputs), training)\n",
    "\n",
    "        #n [K, 1, units]( TODO haha,just like the max polling of conv2d)\n",
    "        aggregated = tf.reduce_max(pointwise, axis=1, keep_dims=True)\n",
    "\n",
    "        # [K, T, units]\n",
    "        repeated = tf.tile(aggregated, [1, cfg.VOXEL_POINT_COUNT, 1])\n",
    "\n",
    "        # [K, T, 2 * units]\n",
    "        concatenated = tf.concat([pointwise, repeated], axis=2)\n",
    "\n",
    "        mask = tf.tile(mask, [1, 1, 2 * self.units])\n",
    "        # TODO use shared mlp,in other means ,expand input as [K, T, 2 * units, 1] conv2d [1, 2 * units, 1, 2 * units]\n",
    "        concatenated = tf.multiply(concatenated, tf.cast(mask, tf.float32))\n",
    "        # [K, T, out_channels]\n",
    "        return concatenated\n",
    "\n",
    "\n",
    "class FeatureNet(object):\n",
    "\n",
    "    def __init__(self, training, batch_size, name=''):\n",
    "        super(FeatureNet, self).__init__()\n",
    "        self.training = training\n",
    "\n",
    "        # scalar\n",
    "        self.batch_size = batch_size\n",
    "        # [ΣK, 35/45, 7]\n",
    "        self.feature = tf.placeholder(\n",
    "            tf.float32, [None, cfg.VOXEL_POINT_COUNT, 7], name='feature')\n",
    "        # [ΣK]\n",
    "        self.number = tf.placeholder(tf.int64, [None], name='number')\n",
    "        # [ΣK, 4], each row stores (batch, d, h, w)\n",
    "        self.coordinate = tf.placeholder(\n",
    "            tf.int64, [None, 4], name='coordinate')\n",
    "\n",
    "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.vfe1 = VFELayer(32, 'VFE-1')\n",
    "            self.vfe2 = VFELayer(128, 'VFE-2')\n",
    "\n",
    "        # boolean mask [K, T, 2 * units] # TODO mask  for what,Sparse tensor representation? How does it work?\n",
    "        mask = tf.not_equal(tf.reduce_max(\n",
    "            self.feature, axis=2, keep_dims=True), 0)\n",
    "        x = self.vfe1.apply(self.feature, mask, self.training)\n",
    "        x = self.vfe2.apply(x, mask, self.training)\n",
    "\n",
    "        # [ΣK, 128]\n",
    "        voxelwise = tf.reduce_max(x, axis=1)\n",
    "        # D' x H' x W' x  C, where C is dimention of voxelwise feature.\n",
    "        # car: [N * 10 * 400 * 352 * 128]\n",
    "        # pedestrian/cyclist: [N * 10 * 200 * 240 * 128]\n",
    "        self.outputs = tf.scatter_nd(\n",
    "            self.coordinate, voxelwise, [self.batch_size, 10, cfg.INPUT_HEIGHT, cfg.INPUT_WIDTH, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/rpn.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding:UTF-8 -*-\n",
    "\n",
    "# File Name : rpn.py\n",
    "# Purpose :\n",
    "# Creation Date : 10-12-2017\n",
    "# Last Modified : Thu 08 Mar 2018 02:20:43 PM CST\n",
    "# Created By : Jialin Zhao\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from config import cfg\n",
    "\n",
    "\n",
    "small_addon_for_BCE = 1e-6\n",
    "\n",
    "\n",
    "class MiddleAndRPN:\n",
    "    def __init__(self, input, alpha=1.5, beta=1, sigma=3, training=True, name=''):\n",
    "        # scale = [batchsize, 10, 400/200, 352/240, 128] should be the output of feature learning network\n",
    "        self.input = input\n",
    "        self.training = training\n",
    "        # groundtruth(target) - each anchor box, represent as △x, △y, △z, △l, △w, △h, rotation\n",
    "        self.targets = tf.placeholder(\n",
    "            tf.float32, [None, cfg.FEATURE_HEIGHT, cfg.FEATURE_WIDTH, 14])\n",
    "        # postive anchors equal to one and others equal to zero(2 anchors in 1 position)\n",
    "        self.pos_equal_one = tf.placeholder(\n",
    "            tf.float32, [None, cfg.FEATURE_HEIGHT, cfg.FEATURE_WIDTH, 2])\n",
    "        self.pos_equal_one_sum = tf.placeholder(tf.float32, [None, 1, 1, 1])\n",
    "        self.pos_equal_one_for_reg = tf.placeholder(\n",
    "            tf.float32, [None, cfg.FEATURE_HEIGHT, cfg.FEATURE_WIDTH, 14])\n",
    "        # negative anchors equal to one and others equal to zero\n",
    "        self.neg_equal_one = tf.placeholder(\n",
    "            tf.float32, [None, cfg.FEATURE_HEIGHT, cfg.FEATURE_WIDTH, 2])\n",
    "        self.neg_equal_one_sum = tf.placeholder(tf.float32, [None, 1, 1, 1])\n",
    "\n",
    "        with tf.variable_scope('MiddleAndRPN_' + name):\n",
    "            # convolutinal middle layers\n",
    "            temp_conv = ConvMD(3, 128, 64, 3, (2, 1, 1),\n",
    "                               (1, 1, 1), self.input, name='conv1')\n",
    "            temp_conv = ConvMD(3, 64, 64, 3, (1, 1, 1),\n",
    "                               (0, 1, 1), temp_conv, name='conv2')\n",
    "            temp_conv = ConvMD(3, 64, 64, 3, (2, 1, 1),\n",
    "                               (1, 1, 1), temp_conv, name='conv3')\n",
    "            temp_conv = tf.transpose(temp_conv, perm=[0, 2, 3, 4, 1])\n",
    "            temp_conv = tf.reshape(\n",
    "                temp_conv, [-1, cfg.INPUT_HEIGHT, cfg.INPUT_WIDTH, 128])\n",
    "\n",
    "            # rpn\n",
    "            # block1:\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (2, 2), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv4')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv5')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv6')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv7')\n",
    "            deconv1 = Deconv2D(128, 256, 3, (1, 1), (0, 0),\n",
    "                               temp_conv, training=self.training, name='deconv1')\n",
    "\n",
    "            # block2:\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (2, 2), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv8')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv9')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv10')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv11')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv12')\n",
    "            temp_conv = ConvMD(2, 128, 128, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv13')\n",
    "            deconv2 = Deconv2D(128, 256, 2, (2, 2), (0, 0),\n",
    "                               temp_conv, training=self.training, name='deconv2')\n",
    "\n",
    "            # block3:\n",
    "            temp_conv = ConvMD(2, 128, 256, 3, (2, 2), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv14')\n",
    "            temp_conv = ConvMD(2, 256, 256, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv15')\n",
    "            temp_conv = ConvMD(2, 256, 256, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv16')\n",
    "            temp_conv = ConvMD(2, 256, 256, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv17')\n",
    "            temp_conv = ConvMD(2, 256, 256, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv18')\n",
    "            temp_conv = ConvMD(2, 256, 256, 3, (1, 1), (1, 1),\n",
    "                               temp_conv, training=self.training, name='conv19')\n",
    "            deconv3 = Deconv2D(256, 256, 4, (4, 4), (0, 0),\n",
    "                               temp_conv, training=self.training, name='deconv3')\n",
    "\n",
    "            # final:\n",
    "            temp_conv = tf.concat([deconv3, deconv2, deconv1], -1)\n",
    "            # Probability score map, scale = [None, 200/100, 176/120, 2]\n",
    "            p_map = ConvMD(2, 768, 2, 1, (1, 1), (0, 0), temp_conv, activation=False,\n",
    "                           training=self.training, name='conv20')\n",
    "            # Regression(residual) map, scale = [None, 200/100, 176/120, 14]\n",
    "            r_map = ConvMD(2, 768, 14, 1, (1, 1), (0, 0),\n",
    "                           temp_conv, training=self.training, activation=False, name='conv21')\n",
    "            # softmax output for positive anchor and negative anchor, scale = [None, 200/100, 176/120, 1]\n",
    "            self.p_pos = tf.sigmoid(p_map)\n",
    "            self.output_shape = [cfg.FEATURE_HEIGHT, cfg.FEATURE_WIDTH]\n",
    "\n",
    "            self.cls_loss = alpha * (-self.pos_equal_one * tf.log(self.p_pos + small_addon_for_BCE)) / self.pos_equal_one_sum \\\n",
    "                + beta * (-self.neg_equal_one * tf.log(1 - self.p_pos +\n",
    "                                                       small_addon_for_BCE)) / self.neg_equal_one_sum\n",
    "            self.cls_loss = tf.reduce_sum(self.cls_loss)\n",
    "\n",
    "            self.reg_loss = smooth_l1(r_map * self.pos_equal_one_for_reg, self.targets *\n",
    "                                      self.pos_equal_one_for_reg, sigma) / self.pos_equal_one_sum\n",
    "            self.reg_loss = tf.reduce_sum(self.reg_loss)\n",
    "\n",
    "            self.loss = tf.reduce_sum(self.cls_loss + self.reg_loss)\n",
    "\n",
    "            self.delta_output = r_map\n",
    "            self.prob_output = self.p_pos\n",
    "\n",
    "\n",
    "def smooth_l1(deltas, targets, sigma=3.0):\n",
    "    sigma2 = sigma * sigma\n",
    "    diffs = tf.subtract(deltas, targets)\n",
    "    smooth_l1_signs = tf.cast(tf.less(tf.abs(diffs), 1.0 / sigma2), tf.float32)\n",
    "\n",
    "    smooth_l1_option1 = tf.multiply(diffs, diffs) * 0.5 * sigma2\n",
    "    smooth_l1_option2 = tf.abs(diffs) - 0.5 / sigma2\n",
    "    smooth_l1_add = tf.multiply(smooth_l1_option1, smooth_l1_signs) + \\\n",
    "        tf.multiply(smooth_l1_option2, 1 - smooth_l1_signs)\n",
    "    smooth_l1 = smooth_l1_add\n",
    "\n",
    "    return smooth_l1\n",
    "\n",
    "\n",
    "def ConvMD(M, Cin, Cout, k, s, p, input, training=True, activation=True, name='conv'):\n",
    "    temp_p = np.array(p)\n",
    "    temp_p = np.lib.pad(temp_p, (1, 1), 'constant', constant_values=(0, 0))\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        if(M == 2):\n",
    "            paddings = (np.array(temp_p)).repeat(2).reshape(4, 2)\n",
    "            pad = tf.pad(input, paddings, \"CONSTANT\")\n",
    "            temp_conv = tf.layers.conv2d(\n",
    "                pad, Cout, k, strides=s, padding=\"valid\", reuse=tf.AUTO_REUSE, name=scope)\n",
    "        if(M == 3):\n",
    "            paddings = (np.array(temp_p)).repeat(2).reshape(5, 2)\n",
    "            pad = tf.pad(input, paddings, \"CONSTANT\")\n",
    "            temp_conv = tf.layers.conv3d(\n",
    "                pad, Cout, k, strides=s, padding=\"valid\", reuse=tf.AUTO_REUSE, name=scope)\n",
    "        temp_conv = tf.layers.batch_normalization(\n",
    "            temp_conv, axis=-1, fused=True, training=training, reuse=tf.AUTO_REUSE, name=scope)\n",
    "        if activation:\n",
    "            return tf.nn.relu(temp_conv)\n",
    "        else:\n",
    "            return temp_conv\n",
    "\n",
    "def Deconv2D(Cin, Cout, k, s, p, input, training=True, name='deconv'):\n",
    "    temp_p = np.array(p)\n",
    "    temp_p = np.lib.pad(temp_p, (1, 1), 'constant', constant_values=(0, 0))\n",
    "    paddings = (np.array(temp_p)).repeat(2).reshape(4, 2)\n",
    "    pad = tf.pad(input, paddings, \"CONSTANT\")\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        temp_conv = tf.layers.conv2d_transpose(\n",
    "            pad, Cout, k, strides=s, padding=\"SAME\", reuse=tf.AUTO_REUSE, name=scope)\n",
    "        temp_conv = tf.layers.batch_normalization(\n",
    "            temp_conv, axis=-1, fused=True, training=training, reuse=tf.AUTO_REUSE, name=scope)\n",
    "        return tf.nn.relu(temp_conv)\n",
    "\n",
    "\n",
    "if(__name__ == \"__main__\"):\n",
    "    m = MiddleAndRPN(tf.placeholder(\n",
    "        tf.float32, [None, 10, cfg.INPUT_HEIGHT, cfg.INPUT_WIDTH, 128]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
